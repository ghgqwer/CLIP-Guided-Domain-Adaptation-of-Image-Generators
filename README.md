# CLIP-Guided-Domain-Adaptation-of-Image-Generators
StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators

**Задача:** Обучение предобученного генератора StyleGAN2 перехода в новый домен без использования реальных изображений из этого домена, используя только текстовое описание.

**Почему важно?**
- Для некоторых доменов невозможно собрать хороший датасет, либо он будет слишком маленьким, поэтому мы хотим обучить модель имзенять стиль изображения без использования картинок в этом стиле


**Почему StyleCLIP не подходит?**  
- StyleCLIP изменяет латентный код самого изображения, но не изменяет сам генератор
 

**Проблемы наивного подхода:**  
- При простой минимизации CLIP-loss между картинкой и текстом, мы в конечном итоге придем к мод коллапсу (будем получать одно и то же изображение) 


## **2. Описание решения**  

Мы хотим не минимизировать расстояние до текста, а хотим изменять латентный код изображения только вдоль текстового промпта, сохраняя индивидуальность изображения

- `G_frozen` (замороженный генератор) — «якорь», сохраняющий исходный домен.  
- `G_train` учится делать изображения, которые отличаются от `G_frozen` только вдоль текстового промпта.  

### ** Adaptive Layer Freezing**  
**Проблема:** При сильных изменениях весов наш генератор сломается и мы получим непонятную кашу (например: собака -> дракон) 

**Решение:**  
1. **Выбор слоёв для обновления:**  
   - Берутся случайные `w ∈ W+.  
   - Делается несколько шагов StyleCLIP-оптимизации для этих `w`.  
   - Выбираются `k` слоёв, где `w` изменился сильнее всего.  

2. **Обучение:**  
   - На каждом шаге обновляем только выбранные слои. 
   - Таким образом у нас получается сохранить целостную структуру генератора.

## **3. Эксперименты**  

**Гиперпараметры**  
- **Learning rate:** 0.002 (Adam).  
- **Количество итераций:**  
  - 300 — для стилей (например, «фото → эскиз»). 
- **Для перехода в латентное пространство**
  - MSE - 0.8
  - LPIPS - 0.5
  - id - 1

## **4. Результаты**  

**Качественные примеры**  
- **Успехи:**  
  - Как мне кажется для 300 шагов хорошо получились переходы к **3D**, **эльфам**, **зомби** и **картинам нарисованным акварелью**
  - <img width="948" height="463" alt="image" src="https://github.com/user-attachments/assets/adcddd7d-99db-4943-a5b4-fccc2fe796ed" />
  - <img width="949" height="457" alt="image" src="https://github.com/user-attachments/assets/bfbdb427-f1f6-48fb-9915-f69b78bd722b" />
  - <img width="944" height="460" alt="image" src="https://github.com/user-attachments/assets/ae6f2a8e-f6fb-4318-92b6-367d7bc2b38b" />
  - <img width="949" height="460" alt="image" src="https://github.com/user-attachments/assets/2b9939bd-fcf5-4a74-b69b-f3df4ad39234" />


- **Неудачи:**  
  - Неудачно получились переходы к **аниме** и **лицу джокера**, думаю нужно увеличить количество итераций, и поиграться с лоссами и их гиперпараметрами
  - Ainme
    - <img width="945" height="463" alt="image" src="https://github.com/user-attachments/assets/d8dd96b1-c9a2-4041-a627-8b6424a3db83" />
  - Jocker
    -<img width="944" height="460" alt="image" src="https://github.com/user-attachments/assets/af80338c-6d03-4139-a903-6c5fa0d28f3d" />
 
  - Плохо получился переход от изображения к его латентному представлению (нужно улучшить подбор гиперпараметров)
  - <img width="949" height="460" alt="image" src="https://github.com/user-attachments/assets/56f119d6-464b-47d0-8845-96f8e2db6639" />


## **5. Выводы**  

 **Что получилось:**  
✅ Адаптация генератора **без данных** через текст.  

➕➖ Инверсия + редактирования (Нужно поработать над переходом изображения в латентное пространство)  

### **Что не получилось:**  
❌ Думаю качество стилизации можно очень сильно улучшить

### **Почему?**  
- Модели слишком мало обучались  
- Лучше подбирать гиперпараметры
- Добавить лоссы для регулизации схожести  
